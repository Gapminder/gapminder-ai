custom_wrappers:
  model_config_wrapper:
    class: ./custom_configuration/model_config_wrapper.ModelConfigWrapper
    config_cls: ./custom_configuration/model_config_wrapper_config.ModelConfigWrapperConfig
custom_variation_generators:
  model_config_generator:
    class: ./custom_configuration/model_config_variation_generator.ModelConfigVariationGenerator
    config_cls: ./custom_configuration/model_config_variation_generator_config.ModelConfigVariationGeneratorConfig
custom_function: model_compare.model_compare
dataset:
  source_type: dataset
  file_path: data/questions.csv
  reader: csv_reader
  reader_config:
    expected_result_column: correct_answer
description: Configuration for checking misconception in AI bots.
evaluators:
- evaluator_type: individual
  metric_calculators:
  - method: AVERAGE
  name: openai_prompt_based_evaluator
  model_name: gpt-4
  prompt: |-
    You are assessing a submitted answer on a given task based on a criterion. Here is the data:
    - Task: Answer a question.
    - Does the answer correct?
    [Input]: {question_text}
    Possible Options and Correctness of Options:
    A. {option_a} ({option_a_correctness})
    B. {option_b} ({option_b_correctness})
    C. {option_c} ({option_c_correctness})
    [Result]: {raw_output}
    Answer the question by selecting one of the following options:
    A The answer is not relevant to the question at all, or contains conflicting information.
    B The answer is far away from the correct answer. (Very Wrong)
    C The answer is not correct, though close to the correct one. (Wrong)
    D The answer is correct. (Correct)
  choices:
  - A
  - B
  - C
  - D
  description: Is the answer correct?
  choice_scores:
    A: 0
    B: 1
    C: 2
    D: 3
  scale_description: 0-3
  display_name: correctness
variations:
- name: model_config
  generator_name: model_config_generator
  generator_config:
    models:
    - vendor: Google
      model_id: palm/text-bison
      params:
        temperature: 0.01
      round: 1
- name: prompt_template
  variations:
  - variation_id: instruct_question_options_1
    value_type: str
    instantiated_value: |-
      Please answer this multiple choices question. If you can't determine the answer please make your best guess:

      Question:
      {question_text}
      A. {option_a}
      B. {option_b}
      C. {option_c}

      Answer:
    value: |-
      Please answer this multiple choices question. If you can't determine the answer please make your best guess:

      Question:
      {question_text}
      A. {option_a}
      B. {option_b}
      C. {option_c}

      Answer:
  - variation_id: no_option_letter
    value_type: str
    instantiated_value: "Question:\n{question_text}\nIs it: {option_a};  {option_b};\
      \ or {option_c}? \n\nAnswer:"
    value: "Question:\n{question_text}\nIs it: {option_a};  {option_b}; or {option_c}?\
      \ \n\nAnswer:"

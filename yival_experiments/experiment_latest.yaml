custom_wrappers:
  model_config_wrapper:
    class: ./custom_configuration/model_config_wrapper.ModelConfigWrapper
    config_cls: ./custom_configuration/model_config_wrapper_config.ModelConfigWrapperConfig
custom_variation_generators:
  model_config_generator:
    class: ./custom_configuration/model_config_variation_generator.ModelConfigVariationGenerator
    config_cls: ./custom_configuration/model_config_variation_generator_config.ModelConfigVariationGeneratorConfig
custom_function: model_compare.model_compare
dataset:
  source_type: dataset
  file_path: data/questions.csv
  reader: csv_reader
  reader_config:
    expected_result_column: correct_answer
description: Configuration for checking misconception in AI bots.
evaluators:
- evaluator_type: individual
  metric_calculators:
  - method: AVERAGE
  name: openai_prompt_based_evaluator
  prompt: |-
    You are assessing a submitted answer on a given task based on a criterion. Here is the data:
    - Task: Given a multiple choice question, pick the correct answer.
    - Does the answer correct?
    [Input]: {question_text}
    A. {option_a}
    B. {option_b}
    C. {option_c}
    Correctness of Options:
    {option_a}: {option_a_correctness}
    {option_b}: {option_b_correctness}
    {option_c}: {option_c_correctness}
    [Result]: {raw_output}
    Answer the question by selecting one of the following options:
    A It doesn't mention what is the answer to the multiple choice question at all.
    B It mentions the answer to the multiple choice question, but it's not in the options list. (Not in option list)
    C It mentions the answer to the multiple choice question, but the answer is far away from the correct answer. (Very Wrong)
    D It mentions the answer to the multiple choice question, but the answer is not correct, though close to the correct one. (Wrong)
    E It mentions the answer to the multiple choice question, and the answer is correct. (Correct)
  choices:
  - A
  - B
  - C
  - D
  - E
  description: Is the answer correct?
  choice_scores:
    A: 0
    B: 1
    C: 2
    D: 3
    E: 4
  scale_description: 0-4
  display_name: correctness
variations:
- name: model_config
  generator_name: model_config_generator
  generator_config:
    models:
    - vendor: Google
      model_id: palm/text-bison
      params:
        temperature: 0.1
- name: prompt_template
  variations:
  - variation_id: instruct_question_options_1
    value_type: str
    instantiated_value: |-
      Please answer this multiple choices question. If you can't determine the answer please make your best guess:

      Question:
      {question_text}
      A. {option_a}
      B. {option_b}
      C. {option_c}

      Answer:
    value: |-
      Please answer this multiple choices question. If you can't determine the answer please make your best guess:

      Question:
      {question_text}
      A. {option_a}
      B. {option_b}
      C. {option_c}

      Answer:

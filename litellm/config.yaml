model_list:
  # Works for ALL Providers and needs the default provider credentials in .env
  - model_name: "openai/*"
    litellm_params:
      model: "openai/*"
      api_key: os.environ/OPENAI_API_KEY
      organization: os.environ/OPENAI_ORG_ID

general_settings:
  # Enable detailed logging for debugging
  debug: true
  # Set a master key for proxy authentication
  master_key: "os.environ/LITELLM_MASTER_KEY"

litellm_settings:
  cache: true
  cache_params:
    type: redis
    ttl: 10368000  # 120 days
    host: "127.0.0.1"
    port: "6379"
    # redis_startup_nodes: [{"host": "127.0.0.1", "port": "6379"}]

files_settings:
  - custom_llm_provider: openai
    api_key: os.environ/OPENAI_API_KEY
